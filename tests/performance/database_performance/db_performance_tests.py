"""
Database performance testing suite for the rental ML system.

Tests database operations, connection pooling, query performance,
and concurrent access patterns under realistic load.
"""

import asyncio
import asyncpg
import redis.asyncio as redis
import time
import random
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import numpy as np
import pytest
from concurrent.futures import ThreadPoolExecutor
import uuid
import json

from ..utils.performance_config import (
    PerformanceConfig, PerformanceTimer, PerformanceMetrics,
    performance_monitor, assert_performance_threshold,
    assert_throughput_threshold, measure_performance
)

logger = logging.getLogger(__name__)


class DatabasePerformanceTester:
    """Comprehensive database performance testing framework."""
    
    def __init__(self, config: Optional[PerformanceConfig] = None):
        self.config = config or PerformanceConfig.from_environment()
        self.db_pool: Optional[asyncpg.Pool] = None
        self.redis_client: Optional[redis.Redis] = None
        self.test_data_created = False
        
    async def setup(self):
        """Setup database connections and test data."""
        await self._create_db_pool()
        await self._create_redis_client()
        await self._create_test_data()
        
    async def teardown(self):
        """Cleanup connections and test data."""
        if self.test_data_created:
            await self._cleanup_test_data()
        
        if self.db_pool:
            await self.db_pool.close()
        
        if self.redis_client:
            await self.redis_client.close()
    
    async def _create_db_pool(self):
        """Create database connection pool."""
        db_config = self.config.database
        self.db_pool = await asyncpg.create_pool(
            host=db_config.host,
            port=db_config.port,
            database=db_config.database,
            user=db_config.username,
            password=db_config.password,
            min_size=5,
            max_size=db_config.pool_size,
            command_timeout=db_config.query_timeout
        )
        logger.info(f"Created database pool with {db_config.pool_size} connections")
    
    async def _create_redis_client(self):
        """Create Redis client."""
        redis_config = self.config.redis
        self.redis_client = redis.from_url(
            f"redis://{redis_config.host}:{redis_config.port}/{redis_config.db}",
            password=redis_config.password,
            max_connections=redis_config.max_connections,
            socket_timeout=redis_config.socket_timeout
        )
        
        # Test connection
        await self.redis_client.ping()
        logger.info("Redis client connected successfully")
    
    async def _create_test_data(self):
        """Create test data for performance testing."""
        logger.info("Creating test data for performance testing...")
        
        async with self.db_pool.acquire() as conn:
            # Create test tables if they don't exist
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS perf_test_users (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    email VARCHAR(255) UNIQUE NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    preferences JSONB,
                    is_active BOOLEAN DEFAULT TRUE
                )
            """)\n            \n            await conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS perf_test_properties (\n                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                    title VARCHAR(255) NOT NULL,\n                    description TEXT,\n                    price DECIMAL NOT NULL,\n                    location VARCHAR(255) NOT NULL,\n                    bedrooms INTEGER NOT NULL,\n                    bathrooms DECIMAL NOT NULL,\n                    amenities TEXT[],\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    is_active BOOLEAN DEFAULT TRUE\n                )\n            \"\"\")\n            \n            await conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS perf_test_interactions (\n                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                    user_id UUID NOT NULL REFERENCES perf_test_users(id),\n                    property_id UUID NOT NULL REFERENCES perf_test_properties(id),\n                    interaction_type VARCHAR(50) NOT NULL,\n                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    metadata JSONB\n                )\n            \"\"\")\n            \n            # Create indexes for performance\n            await conn.execute(\n                \"CREATE INDEX IF NOT EXISTS idx_perf_users_email ON perf_test_users(email)\"\n            )\n            await conn.execute(\n                \"CREATE INDEX IF NOT EXISTS idx_perf_properties_location ON perf_test_properties(location)\"\n            )\n            await conn.execute(\n                \"CREATE INDEX IF NOT EXISTS idx_perf_properties_price ON perf_test_properties(price)\"\n            )\n            await conn.execute(\n                \"CREATE INDEX IF NOT EXISTS idx_perf_interactions_user ON perf_test_interactions(user_id)\"\n            )\n            await conn.execute(\n                \"CREATE INDEX IF NOT EXISTS idx_perf_interactions_property ON perf_test_interactions(property_id)\"\n            )\n            await conn.execute(\n                \"CREATE INDEX IF NOT EXISTS idx_perf_interactions_type ON perf_test_interactions(interaction_type)\"\n            )\n            \n            # Insert test users\n            user_count = 1000\n            user_batch_size = 100\n            \n            for i in range(0, user_count, user_batch_size):\n                batch_size = min(user_batch_size, user_count - i)\n                user_values = []\n                \n                for j in range(batch_size):\n                    user_id = str(uuid.uuid4())\n                    email = f\"testuser{i + j}@example.com\"\n                    preferences = json.dumps({\n                        \"max_price\": random.randint(1000, 5000),\n                        \"preferred_locations\": random.sample([\"SF\", \"NYC\", \"LA\", \"Boston\", \"Seattle\"], 2),\n                        \"min_bedrooms\": random.randint(1, 3)\n                    })\n                    \n                    user_values.append(f\"('{user_id}', '{email}', '{preferences}')\")\n                \n                query = f\"INSERT INTO perf_test_users (id, email, preferences) VALUES {', '.join(user_values)}\"\n                await conn.execute(query)\n            \n            logger.info(f\"Created {user_count} test users\")\n            \n            # Insert test properties\n            property_count = 5000\n            property_batch_size = 200\n            \n            locations = [\"San Francisco\", \"New York\", \"Los Angeles\", \"Boston\", \"Seattle\", \"Chicago\", \"Austin\"]\n            amenities_list = [\n                [\"pool\", \"gym\", \"parking\"],\n                [\"dishwasher\", \"laundry\", \"balcony\"],\n                [\"pet_friendly\", \"gym\", \"roof_deck\"],\n                [\"parking\", \"doorman\", \"elevator\"],\n                [\"pool\", \"concierge\", \"garden\"]\n            ]\n            \n            for i in range(0, property_count, property_batch_size):\n                batch_size = min(property_batch_size, property_count - i)\n                property_values = []\n                \n                for j in range(batch_size):\n                    property_id = str(uuid.uuid4())\n                    title = f\"Test Property {i + j}\"\n                    description = f\"Beautiful test property in {random.choice(locations)}\"\n                    price = random.randint(1000, 8000)\n                    location = random.choice(locations)\n                    bedrooms = random.randint(1, 4)\n                    bathrooms = random.choice([1, 1.5, 2, 2.5, 3])\n                    amenities = random.choice(amenities_list)\n                    \n                    property_values.append(\n                        f\"('{property_id}', '{title}', '{description}', {price}, '{location}', \"\n                        f\"{bedrooms}, {bathrooms}, ARRAY{amenities})\"\n                    )\n                \n                query = (\n                    f\"INSERT INTO perf_test_properties \"\n                    f\"(id, title, description, price, location, bedrooms, bathrooms, amenities) \"\n                    f\"VALUES {', '.join(property_values)}\"\n                )\n                await conn.execute(query)\n            \n            logger.info(f\"Created {property_count} test properties\")\n            \n            # Create user-property interactions\n            interaction_count = 10000\n            interaction_batch_size = 500\n            \n            # Get user and property IDs for interactions\n            user_ids = await conn.fetch(\"SELECT id FROM perf_test_users LIMIT 500\")\n            property_ids = await conn.fetch(\"SELECT id FROM perf_test_properties LIMIT 2000\")\n            \n            interaction_types = [\"view\", \"favorite\", \"contact\", \"share\", \"save\"]\n            \n            for i in range(0, interaction_count, interaction_batch_size):\n                batch_size = min(interaction_batch_size, interaction_count - i)\n                interaction_values = []\n                \n                for j in range(batch_size):\n                    interaction_id = str(uuid.uuid4())\n                    user_id = random.choice(user_ids)['id']\n                    property_id = random.choice(property_ids)['id']\n                    interaction_type = random.choice(interaction_types)\n                    \n                    # Random timestamp within last 30 days\n                    days_ago = random.randint(0, 30)\n                    timestamp = datetime.now() - timedelta(days=days_ago)\n                    \n                    metadata = json.dumps({\n                        \"duration_seconds\": random.randint(10, 300),\n                        \"source\": random.choice([\"web\", \"mobile\", \"api\"])\n                    })\n                    \n                    interaction_values.append(\n                        f\"('{interaction_id}', '{user_id}', '{property_id}', '{interaction_type}', \"\n                        f\"'{timestamp.isoformat()}', '{metadata}')\"\n                    )\n                \n                query = (\n                    f\"INSERT INTO perf_test_interactions \"\n                    f\"(id, user_id, property_id, interaction_type, timestamp, metadata) \"\n                    f\"VALUES {', '.join(interaction_values)}\"\n                )\n                await conn.execute(query)\n            \n            logger.info(f\"Created {interaction_count} test interactions\")\n        \n        self.test_data_created = True\n        logger.info(\"Test data creation completed\")\n    \n    async def _cleanup_test_data(self):\n        \"\"\"Clean up test data.\"\"\"\n        logger.info(\"Cleaning up test data...\")\n        \n        async with self.db_pool.acquire() as conn:\n            await conn.execute(\"DROP TABLE IF EXISTS perf_test_interactions CASCADE\")\n            await conn.execute(\"DROP TABLE IF EXISTS perf_test_properties CASCADE\")\n            await conn.execute(\"DROP TABLE IF EXISTS perf_test_users CASCADE\")\n        \n        logger.info(\"Test data cleanup completed\")\n    \n    async def test_connection_pool_performance(self) -> PerformanceMetrics:\n        \"\"\"Test database connection pool performance.\"\"\"\n        logger.info(\"Testing connection pool performance...\")\n        \n        connection_count = 50\n        connections_per_second = 0\n        \n        with PerformanceTimer(\"connection_pool_test\") as timer:\n            tasks = []\n            \n            async def acquire_and_query():\n                async with self.db_pool.acquire() as conn:\n                    await conn.fetchval(\"SELECT 1\")\n            \n            # Create multiple concurrent connection requests\n            for _ in range(connection_count):\n                task = asyncio.create_task(acquire_and_query())\n                tasks.append(task)\n            \n            await asyncio.gather(*tasks)\n        \n        duration = timer.stop()\n        connections_per_second = connection_count / duration\n        \n        metrics = timer.get_metrics(\n            operations_count=connection_count\n        )\n        \n        # Validate performance\n        assert_throughput_threshold(\n            connections_per_second, \n            20.0, \n            \"Connection pool acquisition\"\n        )\n        \n        logger.info(f\"Connection pool test: {connections_per_second:.1f} connections/sec\")\n        return metrics\n    \n    async def test_simple_query_performance(self) -> Dict[str, PerformanceMetrics]:\n        \"\"\"Test simple query performance.\"\"\"\n        logger.info(\"Testing simple query performance...\")\n        \n        queries = {\n            \"select_by_id\": \"SELECT * FROM perf_test_users WHERE id = $1\",\n            \"select_by_email\": \"SELECT * FROM perf_test_users WHERE email = $1\",\n            \"count_users\": \"SELECT COUNT(*) FROM perf_test_users\",\n            \"select_properties_by_location\": \"SELECT * FROM perf_test_properties WHERE location = $1 LIMIT 10\",\n            \"select_properties_by_price\": \"SELECT * FROM perf_test_properties WHERE price BETWEEN $1 AND $2 LIMIT 10\"\n        }\n        \n        results = {}\n        \n        # Get test data for parameterized queries\n        async with self.db_pool.acquire() as conn:\n            sample_user = await conn.fetchrow(\"SELECT id, email FROM perf_test_users LIMIT 1\")\n            sample_location = await conn.fetchval(\"SELECT location FROM perf_test_properties LIMIT 1\")\n        \n        for query_name, query in queries.items():\n            iterations = 100\n            \n            with PerformanceTimer(f\"simple_query_{query_name}\") as timer:\n                async with self.db_pool.acquire() as conn:\n                    for _ in range(iterations):\n                        if query_name == \"select_by_id\":\n                            await conn.fetchrow(query, sample_user['id'])\n                        elif query_name == \"select_by_email\":\n                            await conn.fetchrow(query, sample_user['email'])\n                        elif query_name == \"count_users\":\n                            await conn.fetchval(query)\n                        elif query_name == \"select_properties_by_location\":\n                            await conn.fetch(query, sample_location)\n                        elif query_name == \"select_properties_by_price\":\n                            await conn.fetch(query, 2000, 4000)\n            \n            duration = timer.stop()\n            queries_per_second = iterations / duration\n            \n            metrics = timer.get_metrics(operations_count=iterations)\n            results[query_name] = metrics\n            \n            # Performance assertions\n            threshold = self.config.thresholds['database_query_time_ms']['simple_select'] / 1000\n            avg_query_time = duration / iterations\n            assert_performance_threshold(avg_query_time, threshold, f\"Simple query {query_name}\")\n            \n            logger.info(f\"Query {query_name}: {queries_per_second:.1f} queries/sec\")\n        \n        return results\n    \n    async def test_complex_query_performance(self) -> Dict[str, PerformanceMetrics]:\n        \"\"\"Test complex query performance.\"\"\"\n        logger.info(\"Testing complex query performance...\")\n        \n        complex_queries = {\n            \"user_interactions_summary\": \"\"\"\n                SELECT \n                    u.id, u.email, \n                    COUNT(i.id) as interaction_count,\n                    AVG(CASE WHEN i.interaction_type = 'view' THEN 1 ELSE 0 END) as view_rate\n                FROM perf_test_users u\n                LEFT JOIN perf_test_interactions i ON u.id = i.user_id\n                WHERE u.created_at > $1\n                GROUP BY u.id, u.email\n                ORDER BY interaction_count DESC\n                LIMIT 50\n            \"\"\",\n            \n            \"property_popularity\": \"\"\"\n                SELECT \n                    p.id, p.title, p.location, p.price,\n                    COUNT(i.id) as total_interactions,\n                    COUNT(CASE WHEN i.interaction_type = 'favorite' THEN 1 END) as favorites,\n                    COUNT(CASE WHEN i.interaction_type = 'view' THEN 1 END) as views\n                FROM perf_test_properties p\n                LEFT JOIN perf_test_interactions i ON p.id = i.property_id\n                WHERE p.price BETWEEN $1 AND $2\n                GROUP BY p.id, p.title, p.location, p.price\n                HAVING COUNT(i.id) > 0\n                ORDER BY total_interactions DESC\n                LIMIT 100\n            \"\"\",\n            \n            \"user_preferences_match\": \"\"\"\n                SELECT DISTINCT\n                    p.id, p.title, p.price, p.location,\n                    u.preferences,\n                    CASE \n                        WHEN p.price <= (u.preferences->>'max_price')::int THEN 1 \n                        ELSE 0 \n                    END as price_match\n                FROM perf_test_properties p\n                CROSS JOIN perf_test_users u\n                WHERE p.location = ANY(\n                    SELECT jsonb_array_elements_text(u.preferences->'preferred_locations')\n                )\n                AND p.bedrooms >= (u.preferences->>'min_bedrooms')::int\n                AND u.is_active = true\n                LIMIT 200\n            \"\"\"\n        }\n        \n        results = {}\n        cutoff_date = datetime.now() - timedelta(days=30)\n        \n        for query_name, query in complex_queries.items():\n            iterations = 10  # Fewer iterations for complex queries\n            \n            with PerformanceTimer(f\"complex_query_{query_name}\") as timer:\n                async with self.db_pool.acquire() as conn:\n                    for _ in range(iterations):\n                        if query_name == \"user_interactions_summary\":\n                            await conn.fetch(query, cutoff_date)\n                        elif query_name == \"property_popularity\":\n                            await conn.fetch(query, 2000, 5000)\n                        elif query_name == \"user_preferences_match\":\n                            await conn.fetch(query)\n            \n            duration = timer.stop()\n            queries_per_second = iterations / duration\n            \n            metrics = timer.get_metrics(operations_count=iterations)\n            results[query_name] = metrics\n            \n            # Performance assertions for complex queries\n            threshold = self.config.thresholds['database_query_time_ms']['complex_join'] / 1000\n            avg_query_time = duration / iterations\n            assert_performance_threshold(avg_query_time, threshold, f\"Complex query {query_name}\")\n            \n            logger.info(f\"Complex query {query_name}: {queries_per_second:.1f} queries/sec\")\n        \n        return results\n    \n    async def test_concurrent_access_performance(self) -> PerformanceMetrics:\n        \"\"\"Test database performance under concurrent access.\"\"\"\n        logger.info(\"Testing concurrent database access...\")\n        \n        concurrent_users = 50\n        operations_per_user = 20\n        total_operations = concurrent_users * operations_per_user\n        \n        async def user_workload(user_id: int):\n            \"\"\"Simulate a user's database workload.\"\"\"\n            operations = [\n                \"read_user\", \"read_properties\", \"create_interaction\", \n                \"read_interactions\", \"update_preferences\"\n            ]\n            \n            for _ in range(operations_per_user):\n                operation = random.choice(operations)\n                \n                async with self.db_pool.acquire() as conn:\n                    if operation == \"read_user\":\n                        await conn.fetch(\n                            \"SELECT * FROM perf_test_users WHERE is_active = true LIMIT 10\"\n                        )\n                    elif operation == \"read_properties\":\n                        location = random.choice([\"San Francisco\", \"New York\", \"Los Angeles\"])\n                        await conn.fetch(\n                            \"SELECT * FROM perf_test_properties WHERE location = $1 LIMIT 10\",\n                            location\n                        )\n                    elif operation == \"create_interaction\":\n                        # Get random user and property\n                        user = await conn.fetchrow(\"SELECT id FROM perf_test_users ORDER BY RANDOM() LIMIT 1\")\n                        prop = await conn.fetchrow(\"SELECT id FROM perf_test_properties ORDER BY RANDOM() LIMIT 1\")\n                        \n                        await conn.execute(\n                            \"\"\"\n                            INSERT INTO perf_test_interactions \n                            (user_id, property_id, interaction_type, metadata)\n                            VALUES ($1, $2, $3, $4)\n                            \"\"\",\n                            user['id'], prop['id'], \"view\", '{\"test\": true}'\n                        )\n                    elif operation == \"read_interactions\":\n                        await conn.fetch(\n                            \"\"\"\n                            SELECT * FROM perf_test_interactions \n                            WHERE timestamp > $1 \n                            ORDER BY timestamp DESC LIMIT 20\n                            \"\"\",\n                            datetime.now() - timedelta(hours=24)\n                        )\n                    elif operation == \"update_preferences\":\n                        user = await conn.fetchrow(\"SELECT id FROM perf_test_users ORDER BY RANDOM() LIMIT 1\")\n                        new_prefs = json.dumps({\"updated\": True, \"timestamp\": time.time()})\n                        await conn.execute(\n                            \"UPDATE perf_test_users SET preferences = $1 WHERE id = $2\",\n                            new_prefs, user['id']\n                        )\n                \n                # Small delay to simulate real usage\n                await asyncio.sleep(0.01)\n        \n        with PerformanceTimer(\"concurrent_access_test\") as timer:\n            # Create concurrent user tasks\n            tasks = [\n                asyncio.create_task(user_workload(i)) \n                for i in range(concurrent_users)\n            ]\n            \n            await asyncio.gather(*tasks)\n        \n        duration = timer.stop()\n        operations_per_second = total_operations / duration\n        \n        metrics = timer.get_metrics(operations_count=total_operations)\n        \n        # Validate concurrent performance\n        assert_throughput_threshold(\n            operations_per_second,\n            self.config.thresholds['throughput_rps']['min_user_operations'],\n            \"Concurrent database operations\"\n        )\n        \n        logger.info(\n            f\"Concurrent access test: {operations_per_second:.1f} ops/sec \"\n            f\"with {concurrent_users} concurrent users\"\n        )\n        \n        return metrics\n    \n    async def test_redis_performance(self) -> Dict[str, PerformanceMetrics]:\n        \"\"\"Test Redis cache performance.\"\"\"\n        logger.info(\"Testing Redis cache performance...\")\n        \n        operations = {\n            \"set_operations\": 1000,\n            \"get_operations\": 2000,\n            \"delete_operations\": 500\n        }\n        \n        results = {}\n        \n        # Test SET operations\n        with PerformanceTimer(\"redis_set_test\") as timer:\n            for i in range(operations[\"set_operations\"]):\n                key = f\"test_key_{i}\"\n                value = json.dumps({\n                    \"id\": i,\n                    \"data\": f\"test_data_{i}\",\n                    \"timestamp\": time.time()\n                })\n                await self.redis_client.set(key, value, ex=3600)  # 1 hour expiry\n        \n        duration = timer.stop()\n        set_ops_per_sec = operations[\"set_operations\"] / duration\n        results[\"set_operations\"] = timer.get_metrics(operations_count=operations[\"set_operations\"])\n        \n        # Test GET operations\n        with PerformanceTimer(\"redis_get_test\") as timer:\n            for i in range(operations[\"get_operations\"]):\n                key = f\"test_key_{i % operations['set_operations']}\"\n                await self.redis_client.get(key)\n        \n        duration = timer.stop()\n        get_ops_per_sec = operations[\"get_operations\"] / duration\n        results[\"get_operations\"] = timer.get_metrics(operations_count=operations[\"get_operations\"])\n        \n        # Test DELETE operations\n        with PerformanceTimer(\"redis_delete_test\") as timer:\n            keys_to_delete = [f\"test_key_{i}\" for i in range(operations[\"delete_operations\"])]\n            await self.redis_client.delete(*keys_to_delete)\n        \n        duration = timer.stop()\n        delete_ops_per_sec = operations[\"delete_operations\"] / duration\n        results[\"delete_operations\"] = timer.get_metrics(operations_count=operations[\"delete_operations\"])\n        \n        # Performance assertions\n        assert_throughput_threshold(set_ops_per_sec, 500.0, \"Redis SET operations\")\n        assert_throughput_threshold(get_ops_per_sec, 1000.0, \"Redis GET operations\")\n        assert_throughput_threshold(delete_ops_per_sec, 200.0, \"Redis DELETE operations\")\n        \n        logger.info(f\"Redis performance - SET: {set_ops_per_sec:.1f}/s, GET: {get_ops_per_sec:.1f}/s, DELETE: {delete_ops_per_sec:.1f}/s\")\n        \n        return results\n    \n    async def run_comprehensive_test(self) -> Dict[str, Any]:\n        \"\"\"Run all database performance tests.\"\"\"\n        logger.info(\"Starting comprehensive database performance test suite...\")\n        \n        results = {\n            \"test_start_time\": datetime.now().isoformat(),\n            \"configuration\": {\n                \"database_pool_size\": self.config.database.pool_size,\n                \"redis_max_connections\": self.config.redis.max_connections\n            }\n        }\n        \n        try:\n            # Connection pool test\n            results[\"connection_pool\"] = (await self.test_connection_pool_performance()).to_dict()\n            \n            # Simple query tests\n            simple_query_results = await self.test_simple_query_performance()\n            results[\"simple_queries\"] = {k: v.to_dict() for k, v in simple_query_results.items()}\n            \n            # Complex query tests\n            complex_query_results = await self.test_complex_query_performance()\n            results[\"complex_queries\"] = {k: v.to_dict() for k, v in complex_query_results.items()}\n            \n            # Concurrent access test\n            results[\"concurrent_access\"] = (await self.test_concurrent_access_performance()).to_dict()\n            \n            # Redis performance test\n            redis_results = await self.test_redis_performance()\n            results[\"redis_operations\"] = {k: v.to_dict() for k, v in redis_results.items()}\n            \n            results[\"test_end_time\"] = datetime.now().isoformat()\n            results[\"overall_status\"] = \"SUCCESS\"\n            \n        except Exception as e:\n            results[\"error\"] = str(e)\n            results[\"overall_status\"] = \"FAILED\"\n            results[\"test_end_time\"] = datetime.now().isoformat()\n            logger.error(f\"Database performance test failed: {e}\")\n            raise\n        \n        logger.info(\"Database performance test suite completed successfully\")\n        return results\n\n\n# Pytest integration\n@pytest.mark.performance\n@pytest.mark.database\n@pytest.mark.asyncio\nasync def test_database_performance_suite():\n    \"\"\"Pytest wrapper for database performance tests.\"\"\"\n    tester = DatabasePerformanceTester()\n    \n    try:\n        await tester.setup()\n        results = await tester.run_comprehensive_test()\n        \n        # Export results\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"database_performance_results_{timestamp}.json\"\n        \n        with open(filename, 'w') as f:\n            json.dump(results, f, indent=2)\n        \n        logger.info(f\"Database performance results exported to {filename}\")\n        \n        # Assert overall success\n        assert results[\"overall_status\"] == \"SUCCESS\"\n        \n    finally:\n        await tester.teardown()\n\n\nif __name__ == \"__main__\":\n    import sys\n    \n    # Configure logging\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    \n    async def main():\n        tester = DatabasePerformanceTester()\n        \n        try:\n            await tester.setup()\n            results = await tester.run_comprehensive_test()\n            \n            # Export results\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            filename = f\"database_performance_results_{timestamp}.json\"\n            \n            with open(filename, 'w') as f:\n                json.dump(results, f, indent=2)\n            \n            print(f\"Database performance test completed. Results saved to {filename}\")\n            print(json.dumps(results, indent=2))\n            \n        finally:\n            await tester.teardown()\n    \n    # Run the tests\n    asyncio.run(main())"